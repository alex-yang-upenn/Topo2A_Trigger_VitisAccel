{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-04 04:28:11.840564: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-04 04:28:22.331256: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"simplified_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 44)]              0         \n",
      "                                                                 \n",
      " dense1 (QDense)             (None, 32)                1440      \n",
      "                                                                 \n",
      " BN1 (QBatchNormalization)   (None, 32)                128       \n",
      "                                                                 \n",
      " relu1 (QActivation)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense2 (QDense)             (None, 16)                528       \n",
      "                                                                 \n",
      " BN2 (QBatchNormalization)   (None, 16)                64        \n",
      "                                                                 \n",
      " relu2 (QActivation)         (None, 16)                0         \n",
      "                                                                 \n",
      " z_mean (QDense)             (None, 3)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,211\n",
      "Trainable params: 2,115\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from qkeras import QActivation, QDense, QConv2D, QBatchNormalization, QConv2DBatchnorm\n",
    "from qkeras import quantized_relu, quantized_bits\n",
    "\n",
    "model_path = '2A_AE_model_V9_BESTOFLONGRUN'\n",
    "custom_objects = {\n",
    "    'QDense': QDense,\n",
    "    'QActivation': QActivation,\n",
    "    'QBatchNormalization': QBatchNormalization\n",
    "}\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/hls4ml/hls4ml/converters/__init__.py:27: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: inputs, layer type: InputLayer, input shapes: [[None, 44]], output shape: [None, 44]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 44]], output shape: [None, 32]\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Layer name: BN1, layer type: QBatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: LeakyReLU, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Layer name: BN2, layer type: QBatchNormalization, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: relu2, layer type: LeakyReLU, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: z_mean, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 3]\n",
      "inputs\n",
      "dense1\n",
      "dense1_linear\n",
      "BN1\n",
      "relu1\n",
      "dense2\n",
      "dense2_linear\n",
      "BN2\n",
      "relu2\n",
      "z_mean\n",
      "z_mean_linear\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "local_module_dir = os.path.join(\"/home/jovyan/work/hls4ml\") # This should be changed the path of the local modified version of HLS4ML containing Vitis Accel backend\n",
    "sys.path.insert(0, local_module_dir)\n",
    "\n",
    "import hls4ml\n",
    "\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity=\"name\")\n",
    "\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "\n",
    "for layer in hls_config['LayerName'].keys():\n",
    "    print(layer)\n",
    "    hls_config['LayerName'][layer]['Trace'] = True\n",
    "    hls_config['LayerName'][layer]['Strategy'] = 'Latency'\n",
    "\n",
    "    if layer == 'inputs':\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<15,6>'\n",
    "    if layer == 'dense1':\n",
    "        hls_config['LayerName'][layer]['Precision']['weight'] = 'ap_fixed<11,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['bias'] = 'ap_fixed<11,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<32,5>'\n",
    "    if layer == \"BN1\":\n",
    "        hls_config['LayerName'][layer]['Precision']['bias'] = 'ap_fixed<14,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<32,5>'\n",
    "    if layer == 'dense2':\n",
    "        hls_config['LayerName'][layer]['Precision']['weight'] = 'ap_fixed<11,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['bias'] = 'ap_fixed<11,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<21,3>'\n",
    "    if layer == \"BN2\":\n",
    "        hls_config['LayerName'][layer]['Precision']['bias'] = 'ap_fixed<14,0>'\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<27,3>'\n",
    "    if layer == 'z_mean':\n",
    "        hls_config['LayerName'][layer]['Precision']['weight'] = 'ap_fixed<11,6>'\n",
    "        hls_config['LayerName'][layer]['Precision']['bias'] = 'ap_fixed<11,6>'\n",
    "        hls_config['LayerName'][layer]['Precision']['result'] = 'ap_fixed<20,1>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: inputs, layer type: InputLayer, input shapes: [[None, 44]], output shape: [None, 44]\n",
      "Layer name: dense1, layer type: QDense, input shapes: [[None, 44]], output shape: [None, 32]\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Layer name: BN1, layer type: QBatchNormalization, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: relu1, layer type: LeakyReLU, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: dense2, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Unsupported quantizer: quantized_po2\n",
      "Unsupported quantizer: quantized_relu_po2\n",
      "Layer name: BN2, layer type: QBatchNormalization, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: relu2, layer type: LeakyReLU, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: z_mean, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 3]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n",
      "\n",
      "\n",
      "Writing Accelerator code\n",
      "Using xilinx_u55c_gen3x16_xdma_3_202210_1 platform\n",
      "WARNING: You set a Part that does not correspond to the Board you specified.The correct Part is now set.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(\n",
    "    model,\n",
    "    hls_config=hls_config,\n",
    "    clock_period=25,\n",
    "    output_dir='vitis_accel_prj',\n",
    "    backend='VitisAccelerator',\n",
    "    board='alveo-u55c',\n",
    "    num_kernel=2,\n",
    "    num_worker=2,\n",
    "    hw_quant=False,\n",
    "    batchsize=8192,\n",
    ")\n",
    "hls_model.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 44)\n",
      "313/313 [==============================] - 2s 5ms/step\n",
      "(10000, 3)\n",
      "(10000, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = np.loadtxt(\"vitis_accel_prj/tb_data/tb_input_features.dat\", delimiter=' ', dtype=np.float32)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_keras = model.predict(X_test)\n",
    "print(y_keras.shape)\n",
    "\n",
    "with open(\"vitis_accel_prj/tb_data/Golden_output.dat\", 'r') as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "y_csim = np.loadtxt(lines, delimiter=' ', dtype=np.float32)\n",
    "print(y_csim.shape)\n",
    "\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_keras.npy\", y_keras)\n",
    "np.save(\"y_csim.npy\", y_csim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy -- hls4ml csim v.s. keras: 0.9599\n",
      "Cosine Similarity -- hls4ml csim v.s. keras: 0.962638795375824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_keras</th>\n",
       "      <th>y_csim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.008644104, 0.0512352, 0.016868591]</td>\n",
       "      <td>[0.00585938, 0.0488281, 0.0107422]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.035419464, 0.0776062, -0.04080963]</td>\n",
       "      <td>[0.0214844, 0.151367, -0.0410156]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.036201477, 0.07720566, -0.042060852]</td>\n",
       "      <td>[0.0224609, 0.15332, -0.0419922]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.00016021729, 0.049575806, -0.0042495728]</td>\n",
       "      <td>[-0.000976563, 0.0478516, -0.00585938]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.002670288, 0.054676056, -0.006164551]</td>\n",
       "      <td>[-0.00292969, 0.0517578, -0.00683594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.013534546, 0.06694412, 0.043159485]</td>\n",
       "      <td>[0.000976563, 0.0419922, 0.0546875]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.007850647, 0.06211853, 0.002040863]</td>\n",
       "      <td>[0.00585938, 0.0537109, -0.000976563]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.095588684, 0.0882225, 0.16547012]</td>\n",
       "      <td>[0.117188, 0.101563, 0.196289]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.017681122, 0.144207, 0.055210114]</td>\n",
       "      <td>[0.00683594, 0.128906, 0.0361328]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.039569855, 0.075473785, -0.04271698]</td>\n",
       "      <td>[0.0527344, 0.12207, 0.0078125]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        y_keras  \\\n",
       "0         [0.008644104, 0.0512352, 0.016868591]   \n",
       "1         [0.035419464, 0.0776062, -0.04080963]   \n",
       "2       [0.036201477, 0.07720566, -0.042060852]   \n",
       "3  [-0.00016021729, 0.049575806, -0.0042495728]   \n",
       "4     [-0.002670288, 0.054676056, -0.006164551]   \n",
       "5        [0.013534546, 0.06694412, 0.043159485]   \n",
       "6        [0.007850647, 0.06211853, 0.002040863]   \n",
       "7          [0.095588684, 0.0882225, 0.16547012]   \n",
       "8          [0.017681122, 0.144207, 0.055210114]   \n",
       "9       [0.039569855, 0.075473785, -0.04271698]   \n",
       "\n",
       "                                   y_csim  \n",
       "0      [0.00585938, 0.0488281, 0.0107422]  \n",
       "1       [0.0214844, 0.151367, -0.0410156]  \n",
       "2        [0.0224609, 0.15332, -0.0419922]  \n",
       "3  [-0.000976563, 0.0478516, -0.00585938]  \n",
       "4   [-0.00292969, 0.0517578, -0.00683594]  \n",
       "5     [0.000976563, 0.0419922, 0.0546875]  \n",
       "6   [0.00585938, 0.0537109, -0.000976563]  \n",
       "7          [0.117188, 0.101563, 0.196289]  \n",
       "8       [0.00683594, 0.128906, 0.0361328]  \n",
       "9         [0.0527344, 0.12207, 0.0078125]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Accuracy -- hls4ml csim v.s. keras: {}\".format(accuracy_score(np.argmax(y_csim, axis=1), np.argmax(y_keras, axis=1))))\n",
    "\n",
    "similarity_matrix = cosine_similarity(y_keras, y_csim)\n",
    "diagonal_similarities = np.diagonal(similarity_matrix)\n",
    "average_similarity = np.mean(diagonal_similarities)\n",
    "print(\"Cosine Similarity -- hls4ml csim v.s. keras: {}\".format(average_similarity))\n",
    "\n",
    "# Create a DataFrame with the first 10 entries of each array\n",
    "df = pd.DataFrame({\n",
    "    \"y_keras\": [entry for entry in y_keras[:10]],\n",
    "    \"y_csim\": [entry for entry in y_csim[:10]]\n",
    "})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
